import streamlit as st
import google.generativeai as genai

# Ù¾ÛŒØ¬ Ú©ÛŒ Ø¨Ù†ÛŒØ§Ø¯ÛŒ ØªØ±ØªÛŒØ¨Ø§Øª
st.set_page_config(page_title="Ø§Ù„Ù…Ø­Ù‚Ù‘Ù‚ AI - Ø¹Ø§Ù„Ù…ÛŒ Ø±ÛŒØ³Ø±Ú† Ø§Ù†Ø¬Ù†", layout="wide")

# Ø®ÙˆØ¨ØµÙˆØ±Øª Ø§Ø±Ø¯Ùˆ ÚˆÛŒØ²Ø§Ø¦Ù† (Nastaleeq Style)
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+Arabic:wght@400;700&display=swap');
    .stApp { direction: rtl; text-align: right; font-family: 'Noto Sans Arabic', sans-serif; }
    .stTextArea textarea { direction: rtl; text-align: right; }
    div.stButton > button { width: 100%; background-color: #075E54; color: white; border-radius: 8px; height: 3em; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ” Ø§Ù„Ù…Ø­Ù‚Ù‘Ù‚ AI: Ø¬Ø§Ù…Ø¹ ÚˆÛŒØ¬ÛŒÙ¹Ù„ Ù„Ø§Ø¦Ø¨Ø±ÛŒØ±ÛŒ Ùˆ Ø¹Ø§Ù„Ù…ÛŒ ØªØ­Ù‚ÛŒÙ‚ÛŒ Ù…Ø±Ú©Ø²")

# Ø³Ø§Ø¦ÛŒÚˆ Ø¨Ø§Ø± Ú©Ù†Ù¹Ø±ÙˆÙ„
with st.sidebar:
    st.header("âš™ï¸ Ø§ÛŒÚˆÙˆØ§Ù†Ø³ Ú©Ù†Ù¹Ø±ÙˆÙ„ Ù¾ÛŒÙ†Ù„")
    raw_api_key = st.text_input("Gemini API Key Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº:", type="password")
    api_key = raw_api_key.strip() if raw_api_key else None
    
    st.markdown("---")
    st.write("### ğŸš€ Ø§ÛŒÙ¾ Ú©ÛŒ Ø®ØµÙˆØµÛŒØ§Øª:")
    st.success("""
    1. **Ù…Ù„Ù¹ÛŒ ÙØ§Ø¦Ù„ Ø³Ù¾ÙˆØ±Ù¹:** ÛØ§Ø±Úˆ ÚˆØ³Ú© Ø³Û’ Ø§ÛŒÚ© Ø³Ø§ØªÚ¾ Ú©Ø¦ÛŒ Ú©ØªØ¨ (PDF) Ù¾Ø± Ø±ÛŒØ³Ø±Ú†Û”
    2. **Ø¹Ø§Ù„Ù…ÛŒ ÙˆÛŒØ¨ Ø³Ø±Ú†:** ÙˆÛŒØ¨ Ù¾Ø± Ù…ÙˆØ¬ÙˆØ¯ ÛØ± Ø²Ø¨Ø§Ù† Ú©Û’ Ù†Ø³Ø®ÙˆÚº ØªÚ© Ø±Ø³Ø§Ø¦ÛŒÛ”
    3. **Ù†Ø³Ø®ÙˆÚº Ú©Ø§ Ù…ÙˆØ§Ø²Ù†Û:** Ù…Ø®ØªÙ„Ù Ù¾Ø¨Ù„Ø´Ø±Ø²ØŒ Ø¬Ù„Ø¯ Ø§ÙˆØ± ØµÙØ­Û Ù†Ù…Ø¨Ø± Ú©ÛŒ ØªÙØ±ÛŒÙ‚Û”
    """)

if api_key:
    try:
        genai.configure(api_key=api_key)
        
        # --- Ø§ÛŒØ±Ø± ÙØ±ÛŒ Ù…Ø§ÚˆÙ„ Ø³Ù„ÛŒÚ©Ù¹Ø± (Fail-Safe Logic) ---
        @st.cache_resource
        def get_working_model():
            try:
                available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
                # ØªØ±Ø¬ÛŒØ­ÛŒ ØªØ±ØªÛŒØ¨ ØªØ§Ú©Û 404 ÛŒØ§ 400 Ù†Û Ø¢Ø¦Û’
                for target in ['models/gemini-1.5-flash', 'models/gemini-1.5-pro', 'models/gemini-pro']:
                    if target in available_models: return target
                return available_models[0]
            except Exception:
                return "gemini-1.5-flash" # ÚˆÛŒÙØ§Ù„Ù¹

        model_name = get_working_model()
        model = genai.GenerativeModel(model_name)
        # --------------------------------------------

        # Ø¢Ù¾Ø´Ù†Ø² Ú©Ø§ Ø§Ù†ØªØ®Ø§Ø¨
        tab1, tab2 = st.tabs(["ğŸ“š Ù…ÛŒØ±ÛŒ Ù„Ø§Ø¦Ø¨Ø±ÛŒØ±ÛŒ (PC/Hard Disk)", "ğŸŒ Ø¹Ø§Ù„Ù…ÛŒ ÙˆÛŒØ¨ Ø±ÛŒØ³Ø±Ú†"])

        with tab1:
            st.subheader("ÛØ§Ø±Úˆ ÚˆØ³Ú© Ø³Û’ Ú©ØªØ¨ Ø§Ù¾ Ù„ÙˆÚˆ Ú©Ø±ÛŒÚº")
            user_files = st.file_uploader("Ø§ÛŒÚ© ÛŒØ§ Ø²Ø§Ø¦Ø¯ PDF ÙØ§Ø¦Ù„ÛŒÚº Ù…Ù†ØªØ®Ø¨ Ú©Ø±ÛŒÚº:", type=['pdf'], accept_multiple_files=True)
            if user_files:
                st.info(f"Ù…Ù†ØªØ®Ø¨ Ø´Ø¯Û Ú©ØªØ¨: {len(user_files)}")

        with tab2:
            st.subheader("Ø¢Ù† Ù„Ø§Ø¦Ù† Ú©ØªØ¨ Ùˆ Ù¾Ø¨Ù„Ø´Ø±Ø² Ù…ÙˆØ§Ø²Ù†Û")
            st.write("Ø§Ø³ Ù¹ÛŒØ¨ Ù…ÛŒÚº Ø¢Ù¾ Ø¨ØºÛŒØ± ÙØ§Ø¦Ù„ Ø§Ù¾ Ù„ÙˆÚˆ Ú©ÛŒÛ’ Ø¨Ø±Ø§ÛÙ Ø±Ø§Ø³Øª Ø§Ù†Ù¹Ø±Ù†ÛŒÙ¹ Ø³Û’ ØªØ­Ù‚ÛŒÙ‚ Ú©Ø± Ø³Ú©ØªÛ’ ÛÛŒÚºÛ”")

        # Ù…Ø´ØªØ±Ú©Û Ø³ÙˆØ§Ù„ Ù†Ø§Ù…Û
        query = st.text_area("Ø¢Ù¾ Ú©Ø§ ØªØ­Ù‚ÛŒÙ‚ÛŒ Ø³ÙˆØ§Ù„ (Ù…Ø«Ù„Ø§Ù‹: ÙÙ„Ø§Ù† Ù…Ø³Ø¦Ù„Û’ Ù¾Ø± Ù…Ø®ØªÙ„Ù Ù†Ø³Ø®ÙˆÚº Ú©Û’ Ø­ÙˆØ§Ù„Û’ Ø¯ÛŒÚº):", height=120)
        
        col1, col2 = st.columns(2)
        with col1:
            target_pub = st.text_input("Ù…Ø®ØµÙˆØµ Ù¾Ø¨Ù„Ø´Ø± (Ù…Ø«Ù„Ø§Ù‹: Ø¯Ø§Ø± Ø§Ù„Ø³Ù„Ø§Ù…ØŒ Ù…Ú©ØªØ¨Û Ø´Ø§Ù…Ù„Û):")
        with col2:
            target_ed = st.text_input("Ø¬Ù„Ø¯ ÛŒØ§ ØµÙØ­Û Ù†Ù…Ø¨Ø± (Ø§Ú¯Ø± Ù…Ø¹Ù„ÙˆÙ… ÛÙˆ):")

        if st.button("Ø¬Ø§Ù…Ø¹ ØªØ­Ù‚ÛŒÙ‚ Ø´Ø±ÙˆØ¹ Ú©Ø±ÛŒÚº"):
            if not query:
                st.warning("Ø¨Ø±Ø§ÛÙ Ú©Ø±Ù… Ø§Ù¾Ù†Ø§ Ø³ÙˆØ§Ù„ Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚºÛ”")
            else:
                with st.spinner(f"Ø§Ù„Ù…Ø­Ù‚Ù‘Ù‚ AI (Ù…Ø§ÚˆÙ„: {model_name}) ÚˆÛŒÙ¹Ø§ Ù¾Ø±ÙˆØ³ÛŒØ³ Ú©Ø± Ø±ÛØ§ ÛÛ’..."):
                    # Ø¹Ø§Ù„Ù…ÛŒ ØªØ­Ù‚ÛŒÙ‚ÛŒ ÛØ¯Ø§ÛŒØ§Øª
                    prompt_context = f"""Ø¢Ù¾ Ø§ÛŒÚ© Ø¹Ø§Ù„Ù…ÛŒ Ø³Ø·Ø­ Ú©Û’ Ù…Ø­Ù‚Ù‚ Ø§ÙˆØ± Ù„Ø§Ø¦Ø¨Ø±ÛŒØ±ÛŒÙ† ÛÛŒÚºÛ” 
                    - ØµØ§Ø±Ù Ú©Û’ Ø³ÙˆØ§Ù„ Ú©Ø§ Ø¬ÙˆØ§Ø¨ Ø§Ù†ØªÛØ§Ø¦ÛŒ Ø¹Ù„Ù…ÛŒ Ø§ÙˆØ± Ù…Ø¯Ù„Ù„ Ø§Ù†Ø¯Ø§Ø² Ù…ÛŒÚº Ø¯ÛŒÚºÛ”
                    - Ø§Ú¯Ø± ÙØ§Ø¦Ù„ÛŒÚº Ù…ÙˆØ¬ÙˆØ¯ ÛÛŒÚº ØªÙˆ Ø§Ù† Ú©Ø§ ÛØ± ØµÙØ­Û Ø¨Ø§Ø±ÛŒÚ©ÛŒ Ø³Û’ Ú†ÛŒÚ© Ú©Ø±ÛŒÚºÛ”
                    - Ø§Ù†Ù¹Ø±Ù†ÛŒÙ¹ Ø³Û’ Ø§Ø³ Ú©ØªØ§Ø¨ Ú©Û’ ØªÙ…Ø§Ù… Ø¯Ø³ØªÛŒØ§Ø¨ Ù†Ø³Ø®ÙˆÚº (Ø·Ø¨Ø¹) Ú©Ø§ Ù…ÙˆØ§Ø²Ù†Û Ú©Ø±ÛŒÚºÛ”
                    - Ù¾Ø¨Ù„Ø´Ø±: {target_pub} Ø§ÙˆØ± Ø§ÛŒÚˆÛŒØ´Ù†: {target_ed} Ú©Ùˆ ØªØ±Ø¬ÛŒØ­ Ø¯ÛŒÚºÛ”
                    - Ø¬ÙˆØ§Ø¨ Ù…ÛŒÚº Ú©ØªØ§Ø¨ØŒ Ù…ØµÙ†ÙØŒ Ù¾Ø¨Ù„Ø´Ø±ØŒ Ø¬Ù„Ø¯ Ø§ÙˆØ± ØµÙØ­Û Ù†Ù…Ø¨Ø± Ú©Ø§ Ø­ÙˆØ§Ù„Û Ù„Ø§Ø²Ù…ÛŒ Ø¯ÛŒÚºÛ”"""

                    try:
                        if user_files and any(f for f in user_files):
                            # Ù…Ù„Ù¹ÛŒ ÙØ§Ø¦Ù„ Ù¾Ø±ÙˆØ³ÛŒØ³Ù†Ú¯
                            request_data = []
                            for f in user_files:
                                request_data.append({"mime_type": "application/pdf", "data": f.read()})
                            request_data.append(prompt_context + "\n" + query)
                            response = model.generate_content(request_data)
                        else:
                            # Ø®Ø§Ù„Øµ ÙˆÛŒØ¨ Ø±ÛŒØ³Ø±Ú†
                            response = model.generate_content(prompt_context + "\n" + query)
                        
                        st.markdown("### ğŸ“œ ØªØ­Ù‚ÛŒÙ‚ÛŒ Ø±Ù¾ÙˆØ±Ù¹:")
                        st.write(response.text)
                        
                    except Exception as e:
                        st.error(f"ØªØ­Ù‚ÛŒÙ‚ Ú©Û’ Ø¯ÙˆØ±Ø§Ù† Ø®Ø±Ø§Ø¨ÛŒ: {str(e)}")
                        st.info("Ù…Ø´ÙˆØ±Û: Ø§Ú¯Ø± 400 Ø§ÛŒØ±Ø± Ø¢Ø¦Û’ ØªÙˆ Ø§Ù¾Ù†ÛŒ API Key Ø¯ÙˆØ¨Ø§Ø±Û Ú†ÛŒÚ© Ú©Ø±ÛŒÚº ÛŒØ§ Ú†Ú¾ÙˆÙ¹ÛŒ ÙØ§Ø¦Ù„ Ø³Û’ Ù¹ÛŒØ³Ù¹ Ú©Ø±ÛŒÚºÛ”")

    except Exception as e:
        st.error(f"Ø³Ø³Ù¹Ù… Ú©Ù†Ú©Ø´Ù† Ø§ÛŒØ±Ø±: {e}")
else:
    st.warning("ØªØ­Ù‚ÛŒÙ‚ Ø´Ø±ÙˆØ¹ Ú©Ø±Ù†Û’ Ú©Û’ Ù„ÛŒÛ’ Ø³Ø§Ø¦ÛŒÚˆ Ø¨Ø§Ø± Ù…ÛŒÚº Ø§Ù¾Ù†ÛŒ 'Gemini API Key' Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚºÛ”")
